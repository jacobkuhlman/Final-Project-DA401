{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from langdetect import detect\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Combining the Tweet data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Reading in October data \n",
    "October_26 = pd.read_excel('/Users/jacobkuhlman/Desktop/BITCOIN DATA FINAL/Combined Data/October_26_Data.xlsx')\n",
    "October_27 = pd.read_excel('/Users/jacobkuhlman/Desktop/BITCOIN DATA FINAL/Combined Data/October_27_Data.xlsx')\n",
    "October_28 = pd.read_excel('/Users/jacobkuhlman/Desktop/BITCOIN DATA FINAL/Combined Data/October_28_Data.xlsx')\n",
    "October_29 = pd.read_excel('/Users/jacobkuhlman/Desktop/BITCOIN DATA FINAL/Combined Data/October_29_Data.xlsx')\n",
    "October_30 = pd.read_excel('/Users/jacobkuhlman/Desktop/BITCOIN DATA FINAL/Combined Data/October_30_Data.xlsx')\n",
    "October_31 = pd.read_excel('/Users/jacobkuhlman/Desktop/BITCOIN DATA FINAL/Combined Data/October_31_Data.xlsx')\n",
    "\n",
    "# Reading in November data \n",
    "November_1 = pd.read_excel('/Users/jacobkuhlman/Desktop/BITCOIN DATA FINAL/Combined Data/November_1_Data.xlsx')\n",
    "November_2 = pd.read_excel('/Users/jacobkuhlman/Desktop/BITCOIN DATA FINAL/Combined Data/November_2_Data.xlsx')\n",
    "November_3 = pd.read_excel('/Users/jacobkuhlman/Desktop/BITCOIN DATA FINAL/Combined Data/November_3_Data.xlsx')\n",
    "November_4 = pd.read_excel('/Users/jacobkuhlman/Desktop/BITCOIN DATA FINAL/Combined Data/November_4_Data.xlsx')\n",
    "November_5 = pd.read_excel('/Users/jacobkuhlman/Desktop/BITCOIN DATA FINAL/Combined Data/November_5_Data.xlsx')\n",
    "November_6 = pd.read_excel('/Users/jacobkuhlman/Desktop/BITCOIN DATA FINAL/Combined Data/November_6_Data.xlsx')\n",
    "November_7 = pd.read_excel('/Users/jacobkuhlman/Desktop/BITCOIN DATA FINAL/Combined Data/November_7_Data.xlsx')\n",
    "November_8 = pd.read_excel('/Users/jacobkuhlman/Desktop/BITCOIN DATA FINAL/Combined Data/November_8_Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combined_Data = pd.concat([November_1,November_2, November_3, November_4, November_5, November_6, November_7,November_8,\n",
    "                            October_26, October_27, October_28, October_29, October_30, October_31], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Functions used in the notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for renamming columns \n",
    "def rename_column(oldName, newName, df):\n",
    "    New = df.rename(columns={oldName: newName})\n",
    "    return New\n",
    "\n",
    "# Function for dropping columns \n",
    "def drop(df, column):\n",
    "    df = df.drop([column], axis=1)\n",
    "    return df \n",
    "\n",
    "# Function for cleaning the tweets \n",
    "def cleaner(tweet):\n",
    "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #Remove @ sign\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
    "    tweet = \" \".join(tweet.split())\n",
    "     #Remove Emojis\n",
    "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \").replace(\"RT\", \" \").replace(\":\", \" \") #Remove hashtag sign but keep the text\n",
    "    #tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) \\\n",
    "         #if w.lower() in words or not w.isalpha())\n",
    "    return tweet\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags \n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Data manipulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnamed column \n",
    "Combined_Data = Combined_Data.loc[:, ~Combined_Data.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Cleaing the tweets: Taking @ out, taking links out etc. \n",
    "Combined_Data['Clean_Tweet'] = Combined_Data['Tweet'].map(lambda x: cleaner(x))\n",
    "\n",
    "Combined_Data['Clean_Tweet'] = Combined_Data['Clean_Tweet']\n",
    "\n",
    "# Making the cleaned tweet column all lower case \n",
    "Combined_Data[\"Clean_Tweet\"] = Combined_Data[\"Clean_Tweet\"].str.lower()\n",
    "\n",
    "\n",
    "\n",
    "# Remove punctuation from the tweet column \n",
    "Combined_Data[\"Clean_Tweet\"] = Combined_Data[\"Clean_Tweet\"].str.replace('[^\\w\\s]','')\n",
    "\n",
    "# Remove emojis from tweet column \n",
    "Combined_Data[\"Clean_Tweet\"] = Combined_Data[\"Clean_Tweet\"].apply(lambda x: remove_emoji(x))\n",
    "\n",
    "# Changing the order of columns in the dataframe \n",
    "Combined_Data = Combined_Data[['Date', 'ID', 'Author ID', 'Tweet', 'Clean_Tweet', 'public_metrics', 'entities', 'Language']]\n",
    "\n",
    "\n",
    "# creating new columns from the 'public_metrics' column that was collected from twitter \n",
    "Combined_Data[['retweet_count', 'reply_count', 'like_count', 'quote_count']] = Combined_Data['public_metrics'].str.split(',', 4, expand=True)\n",
    "\n",
    "\n",
    "# getting only the numbers extracted for these columns \n",
    "Combined_Data['retweet_count'] = Combined_Data['retweet_count'].str[17:]\n",
    "Combined_Data['reply_count'] = Combined_Data['reply_count'].str[15:]\n",
    "Combined_Data['like_count'] = Combined_Data['like_count'].str[14:]\n",
    "\n",
    "# dropping un-needed columns \n",
    "Combined_Data = drop(Combined_Data, 'entities')\n",
    "Combined_Data = drop(Combined_Data, 'quote_count')\n",
    "Combined_Data = drop(Combined_Data, 'public_metrics')\n",
    "Combined_Data = drop(Combined_Data, 'Language')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Converting data to excel file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combined_Data.to_excel(\"Combined_Data.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
